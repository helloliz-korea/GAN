{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################################################################################################################\n",
    "# ## get device configuration ...\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# ## print('    [!] number of usable devices: ', len(physical_devices))\n",
    "# device_id = 0\n",
    "# world_size = 1\n",
    "\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[device_id], True)\n",
    "# tf.config.experimental.set_visible_devices(physical_devices[device_id], 'GPU')\n",
    "# ##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "# example of pix2pix gan for satellite to map image-to-image translation\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import Input, Model\n",
    "from keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Activation, Concatenate, Dropout, BatchNormalization\n",
    "\n",
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# source image input\n",
    "\tin_src_image = Input(shape=image_shape)\n",
    "\t# target image input\n",
    "\tin_target_image = Input(shape=image_shape)\n",
    "\t# concatenate images channel-wise\n",
    "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
    "\t# C64\n",
    "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C512\n",
    "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# second last output layer\n",
    "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# patch output\n",
    "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\tpatch_out = Activation('sigmoid')(d)\n",
    "\t# define model\n",
    "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
    "\t# compile model\n",
    "\topt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "\treturn model\n",
    "\n",
    "# define an encoder block\n",
    "def encoder_block(layer_in, n_filters, s, batchnorm=True):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# add downsampling layer\n",
    "\tg = Conv2D(n_filters, (4,4), strides=(s,s), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# conditionally add batch normalization\n",
    "\tif batchnorm:\n",
    "\t\tg = BatchNormalization()(g, training=True)\n",
    "\t# leaky relu activation\n",
    "\tg = LeakyReLU(alpha=0.2)(g)\n",
    "\treturn g\n",
    "\n",
    "# define a resnet block\n",
    "def resnet_block(n_filters, input_layer, batchnorm=True):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# first layer convolutional layer\n",
    "\tg = Conv2D(n_filters, (4,4), strides=(1,1), padding='same', kernel_initializer=init)(input_layer)\n",
    "\tif batchnorm:\n",
    "\t\tg = BatchNormalization()(g, training=True)\n",
    "\tg = LeakyReLU(alpha=0.2)(g)\n",
    "\t# second convolutional layer\n",
    "\tg = Conv2D(n_filters, (4,4), strides=(1,1), padding='same', kernel_initializer=init)(g)\n",
    "\tif batchnorm:\n",
    "\t\tg = BatchNormalization()(g, training=True)\n",
    "\t# concatenate merge channel-wise with input layer\n",
    "\tg = Concatenate()([g, input_layer])\n",
    "\treturn g\n",
    "\n",
    "# define a decoder block\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# add upsampling layer\n",
    "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# add batch normalization\n",
    "\tg = BatchNormalization()(g, training=True)\n",
    "\t# conditionally add dropout\n",
    "\tif dropout:\n",
    "\t\tg = Dropout(0.5)(g, training=True)\n",
    "\t# merge with skip connection\n",
    "\tg = Concatenate()([g, skip_in])\n",
    "\t# relu activation\n",
    "\tg = Activation('relu')(g)\n",
    "\treturn g\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(224,224)):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# image input\n",
    "\tin_image = Input(shape=image_shape) \n",
    "\t# encoder model\n",
    "\te1 = encoder_block(in_image, 64, 2, batchnorm=False) #112\n",
    "\n",
    "\te2 = encoder_block(e1, 2, 128) #56\n",
    "\tfor _ in range(3):\n",
    "\t\tr2 = resnet_block(128, e2)  \n",
    "\tact2 = LeakyReLU(alpha=0.2)(r2) \n",
    "\t\n",
    "\te3 = encoder_block(act2, 2, 256) #28\n",
    "\tfor _ in range(4):\n",
    "\t\tr3 = resnet_block(256, e3) \n",
    "\tact3 = LeakyReLU(alpha=0.2)(r3) \n",
    "\n",
    "\te4 = encoder_block(act3, 2, 512) #14\n",
    "\tfor _ in range(6):\n",
    "\t\tr4 = resnet_block(512, e4) \n",
    "\tact4 = LeakyReLU(alpha=0.2)(r4) \n",
    "\n",
    "\t# bottleneck, no batch norm and relu\n",
    "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(act4) #7\n",
    "\tb = Activation('relu')(b)  \n",
    "\n",
    "\t# decoder model\n",
    "\td4 = decoder_block(b, act4, 512) #14\n",
    "\td3 = decoder_block(d4, act3, 256)  #28\n",
    "\td2 = decoder_block(d3, act2, 128, dropout=False) #56\n",
    "\td1 = decoder_block(d2, e1, 64, dropout=False) #112\n",
    "\n",
    "\t# output\n",
    "\tg = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d1)\n",
    "\tout_image = Activation('sigmoid')(g)\n",
    "\t# define model\n",
    "\tmodel = Model(in_image, out_image)\n",
    "\treturn model\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model, image_shape):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tfor layer in d_model.layers:\n",
    "\t\tif not isinstance(layer, BatchNormalization):\n",
    "\t\t\tlayer.trainable = False\n",
    "\t# define the source image\n",
    "\tin_src = Input(shape=image_shape)\n",
    "\t# connect the source image to the generator input\n",
    "\tgen_out = g_model(in_src)\n",
    "\t# connect the source input and generator output to the discriminator input\n",
    "\tdis_out = d_model([in_src, gen_out])\n",
    "\t# src image as input, generated image and classification output\n",
    "\tmodel = Model(in_src, [dis_out, gen_out])\n",
    "\t# compile model\n",
    "\topt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)  # 원래 베타값 0.5\n",
    "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_real_samples(filename):\n",
    "\t# load compressed arrays\n",
    "\tdata = load(filename)\n",
    "\t# unpack arrays\n",
    "\tX1, X2 = data['arr_0'], data['arr_1']\n",
    "\treturn [X1, X2]\n",
    "\n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "\t# unpack dataset\n",
    "\ttrainA, trainB = dataset\n",
    "\t# choose random instances\n",
    "\tix = randint(0, trainA.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX1, X2 = trainA[ix], trainB[ix]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "\treturn [X1, X2], y\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "\t# generate fake instance\n",
    "\tX = g_model.predict(samples)\n",
    "\t# create 'fake' class labels (0)\n",
    "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, d_model, g_model, gan_model, dataset, n_samples=3):\n",
    "\t# select a sample of input images\n",
    "\t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n",
    "\t# generate a batch of fake samples\n",
    "\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "\t# plot real source images\n",
    "\tfor i in range(n_samples):\n",
    "\t\tplt.subplot(3, n_samples, 1 + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(X_realA[i])   # input image\n",
    "\t# plot generated target image\n",
    "\tfor i in range(n_samples):\n",
    "\t\tplt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(X_fakeB[i])   # predict image\n",
    "\t# plot real target image\n",
    "\tfor i in range(n_samples):\n",
    "\t\tplt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(X_realB[i])   # ground truth image\n",
    "\t# save plot to file\n",
    "\tfilename1 = 'plot_%07d.png' % (step+1)\n",
    "\tplt.savefig(filename1)\n",
    "\tplt.close()\n",
    "\t# save the generator model\n",
    "\tfilename2 = 'g_model_%07d.h5' % (step+1)\n",
    "\tg_model.save(filename2)\n",
    "\tfilename3 = 'gan_model_%07d.h5' % (step+1)\n",
    "\tgan_model.save(filename3)\n",
    "\tfilename4 = 'd_model_%07d.h5' % (step+1)\n",
    "\td_model.save(filename4)\n",
    "\tprint('>Saved: %s, %s and %s' % (filename1, filename2, filename3))\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "import pickle\n",
    "# train pix2pix models  # 27720 data files\n",
    "def train(d_model, g_model, gan_model, dataset, n_epochs=50, n_batch=1):\n",
    "\t# determine the output square shape of the discriminator\n",
    "\tt = time.time()\n",
    "\tn_patch = d_model.output_shape[1]\n",
    "\t# unpack dataset\n",
    "\ttrainA, _ = dataset\n",
    "\t# calculate the number of batches per training epoch\n",
    "\tbat_per_epo = int(len(trainA) / n_batch)   # bat_per_epoch = 27720\n",
    "\t# calculate the number of training iterations\n",
    "\tn_steps = bat_per_epo * n_epochs    # 27720*15 = 415800 step\n",
    "\t# manually enumerate epochs\n",
    "\tD_loss, G_loss = {}, {}\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# select a batch of real samples\n",
    "\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    "\t\t# generate a batch of fake samples\n",
    "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "\t\t# update discriminator for real samples\n",
    "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "\t\t# update discriminator for generated samples\n",
    "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "\t\td_loss = (d_loss1 + d_loss2) / 2\n",
    "\t\t# update the generator\n",
    "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "\t\tD_loss.setdefault(i, d_loss)\n",
    "\t\tG_loss.setdefault(i, g_loss)\n",
    "\t\t# summarize performance\n",
    "\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss), (time.time() - t)/60, \" minute\")\n",
    "\t\t# summarize model performance\n",
    "\t\tif (i+1) % (bat_per_epo) == 0:\n",
    "\t\t\tsummarize_performance(i, d_model, g_model, gan_model, dataset)\n",
    "\t\t\ttitles_ = ['Discriminator Loss', 'Generator Loss']\n",
    "\t\t\tfig_, ax_ = plt.subplots(2, 1, figsize=(12, 6*2))\n",
    "\t\t\tax_[0].plot(D_loss.keys(), D_loss.values())\n",
    "\t\t\tax_[1].plot(G_loss.keys(), G_loss.values())\n",
    "\t\t\tax_[0].set_title(titles_[0])\n",
    "\t\t\tax_[1].set_title(titles_[1])\n",
    "\t\t\tfilename_ = 'loss_ep_%07d.png' % (i+1)\n",
    "\t\t\tplt.savefig(filename_)\n",
    "\t\t\tplt.close()\n",
    "\ttitles = ['Discriminator Loss', 'Generator Loss']\n",
    "\tfig, ax = plt.subplots(2, 1, figsize=(12, 6*2))\n",
    "\tax[0].plot(D_loss.keys(), D_loss.values())\n",
    "\tax[1].plot(G_loss.keys(), G_loss.values())\n",
    "\tax[0].set_title(titles[0])\n",
    "\tax[1].set_title(titles[1])\n",
    "\tfilename = 'loss_%07d.png' % (n_steps)\n",
    "\tplt.savefig(filename)\n",
    "\tplt.close()\n",
    "\twith open('d_loss_%07d.pkl' % (n_steps), 'wb') as f:\n",
    "\t\tpickle.dump(D_loss, f)\n",
    "\twith open('g_loss_%07d.pkl' % (n_steps), 'wb') as f:\n",
    "\t\tpickle.dump(G_loss, f)\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "# load image data   \n",
    "dataset = load_real_samples('*.npz')\n",
    "print('Loaded', dataset[0].shape, dataset[1].shape)\n",
    "\n",
    "# define input shape based on the loaded dataset\n",
    "image_shape = dataset[0].shape[1:]\n",
    "\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "# g_model = define_generator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "\n",
    "# train model\n",
    "train(d_model, g_model, gan_model, dataset)\n",
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from keras.models import load_model\n",
    "\n",
    "# # load model\n",
    "# model = load_model('model_0277200.h5')\n",
    "# train_dt = load_real_samples('train_224_J.npz')\n",
    "# test_dt = load_real_samples('test_224_J.npz')\n",
    "# model.summary()\n",
    "#loss, acc = model.evaluate(test_dt[0], test_dt[1], verbose=1)\n",
    "\n",
    "# model_history = pd.DataFrame(model.history)\n",
    "# model_history[2] = model.n_steps\n",
    "\n",
    "# fig, ax = plt.subplots(1, figsize=(8,6))\n",
    "# num_epochs = model_history.shape[0]\n",
    "\n",
    "# ax.plot(np.arange(0, num_epochs), model_history[\"mae\"], \n",
    "#         label=\"Training MAE\")\n",
    "# # ax.plot(np.arange(0, num_epochs), model_history[\"val_mae\"], \n",
    "# #         label=\"Validation MAE\")\n",
    "# ax.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# # 캔버스 사이즈 적용\n",
    "# plt.rcParams[\"figure.figsize\"] = (12, 9)\n",
    "# x = ...\n",
    "# sns.distplot(x)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_dt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = list(zip(train_dt[0], train_dt[1]))\n",
    "# print(len(x))\n",
    "# x1 = np.random.choice(27720, 2772)\n",
    "# x2 = np.random.choice(27720, 2772)\n",
    "# x3 = np.random.choice(27720, 2772)\n",
    "# print(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = (12, 9)\n",
    "# sns.distplot(x1)\n",
    "# sns.distplot(x2)\n",
    "# sns.distplot(x3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov  4 2022, 13:42:51) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02aaae3c9b50b62c88d0cc652c4ef3b1b4bf05515e9d7a066ea77f7c79246682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
