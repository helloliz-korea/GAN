{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import UNetGenerator, Discriminator\n",
    "# from nested_unet_model import nUNetGenerator, Discriminator\n",
    "\n",
    "generator = UNetGenerator()\n",
    "# generator = nUNetGenerator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "\n",
    "bce = losses.BinaryCrossentropy(from_logits=False)\n",
    "mae = losses.MeanAbsoluteError()\n",
    "\n",
    "def get_gene_loss(fake_output, real_output, fake_disc):\n",
    "    l1_loss = mae(real_output, fake_output)\n",
    "    gene_loss = bce(tf.ones_like(fake_disc), fake_disc)\n",
    "    return gene_loss, l1_loss\n",
    "\n",
    "def get_disc_loss(fake_disc, real_disc):\n",
    "    return bce(tf.zeros_like(fake_disc), fake_disc) + bce(tf.ones_like(real_disc), real_disc)\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "gene_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)\n",
    "disc_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    with tf.GradientTape() as gene_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generator 예측 = fake\n",
    "        gen_inp = generator(inp, training=True)\n",
    "        # Discriminator 예측\n",
    "        fake_disc = discriminator(inp, gen_inp, training=True)\n",
    "        real_disc = discriminator(inp, tar, training=True)\n",
    "        # Generator 손실 계산\n",
    "        gene_loss, l1_loss = get_gene_loss(gen_inp, tar, fake_disc)\n",
    "        gene_total_loss = gene_loss + (100 * l1_loss) ## <===== L1 손실 반영 λ=100\n",
    "        # Discrminator 손실 계산\n",
    "        disc_loss = get_disc_loss(fake_disc, real_disc)\n",
    "                \n",
    "    gene_gradient = gene_tape.gradient(gene_total_loss, generator.trainable_variables)\n",
    "    disc_gradient = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    gene_opt.apply_gradients(zip(gene_gradient, generator.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(disc_gradient, discriminator.trainable_variables))\n",
    "    return gene_loss, l1_loss, disc_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. 저장할 폴더와 형식을 선택\n",
    "ckpt_directory = \"체크포인트 디렉토리 경로\"\n",
    "#### epoch로 파일이름 저장\n",
    "ckpt_path = ckpt_directory+\"/체크포인트_파일명.ckpt\" \n",
    "\n",
    "checkpoint_prefix = os.path.join(ckpt_path)\n",
    "checkpoint = tf.train.Checkpoint(unet_optimizer=gene_opt,\n",
    "                                 discriminator_optimizer=disc_opt,\n",
    "                                 unet=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `data.Dataset.list_files` : https://soki.tistory.com/m/20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 업로드 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200   \n",
    "n_batch = 10\n",
    "\n",
    "from numpy import load\n",
    "# load and prepare training images\n",
    "def load_real_samples(filename):\n",
    "    # load compressed arrays\n",
    "    data = load(filename)\n",
    "    # unpack arrays\n",
    "    X1, X2 = data['arr_0'], data['arr_1']\n",
    "    return [X1, X2]\n",
    "\n",
    "dataset = load_real_samples('데이터셋_파일명')\n",
    "print(dataset[0].shape)\n",
    "\n",
    "from numpy.random import randint\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# unpack dataset\n",
    "\ttrainA, trainB = dataset\n",
    "\t# choose random instances\n",
    "\tix = randint(0, trainA.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX1, X2 = trainA[ix], trainB[ix]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = ones((n_samples, 16,16,1))\n",
    "\treturn [X1, X2], y\n",
    "\n",
    "import time\n",
    "## 1에폭당 학습 스텝\n",
    "n_steps = int(len(dataset[0]) / n_batch)\n",
    "\n",
    "ep_list, g_list, d_list = [], [], []\n",
    "for epoch in range(1, EPOCHS+1):    \n",
    "    t = time.time()\n",
    "    for i in range(n_steps):\n",
    "        [inp, tar], y_real = generate_real_samples(dataset, n_batch)\n",
    "        g_loss, l1_loss, d_loss = train_step(inp, tar)\n",
    "\n",
    "        # 10회 반복마다 손실을 출력합니다.        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"EPOCH[{epoch}] - STEP[{i+1}] \\\n",
    "                    \\nGenerator_loss:{g_loss.numpy():.4f}, L1_loss:{l1_loss.numpy():.4f} \\\n",
    "                    \\nDiscriminator_loss:{d_loss.numpy():.4f}, \", (time.time()-t)/60, \" minute\", end=\"\\n\\n\")\n",
    "        if (i+1) % n_steps == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "            ep_list.append(epoch)\n",
    "            g_list.append(g_loss)\n",
    "            d_list.append(d_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 진행에 따른 generator/discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss_dict = dict(zip(ep_list, g_list))\n",
    "# print(gloss_dict.keys())\n",
    "dloss_dict = dict(zip(ep_list, d_list))\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "#ax.set_xticks(list(range(EPOCHS)), gloss_dict.keys())\n",
    "xticks = [5*i for i in range(1,int(EPOCHS/5)+1)]\n",
    "ax.set_xticks(xticks)\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "plt.plot(gloss_dict.values(), label='generator loss')\n",
    "plt.plot(dloss_dict.values(), label='discriminator loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 후 source/ generated/ ground truth 랜덤 이미지 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "ix = randint(0, len(dataset[0]), 1)\n",
    "inp, tar = dataset[0][ix], dataset[1][ix] #.reshape(512,512,1)\n",
    "print(inp.shape)\n",
    "\n",
    "pred = generator(inp)\n",
    "\n",
    "title = ['Source', 'Generated', 'Expected']\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10*3, 10))\n",
    "ax[0].imshow(np.squeeze(inp))\n",
    "ax[1].imshow(np.squeeze(pred))\n",
    "ax[2].imshow(np.squeeze(tar))\n",
    "ax[0].set_title(title[0], fontsize=30)\n",
    "ax[1].set_title(title[1], fontsize=30)\n",
    "ax[2].set_title(title[2], fontsize=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증 데이터에 대한 예측 이미지 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dt = load_real_samples('valid_a.npz')\n",
    "print(valid_dt[0].shape)\n",
    "\n",
    "pred_img = []\n",
    "for s in valid_dt[0]:\n",
    "    pred = generator(s.reshape(1,512,512,1))\n",
    "    pred_img.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 예측이미지 데이터 shape 확인\n",
    "pred_img = np.array(pred_img).reshape(800,512,512,1)\n",
    "print(pred_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files : (source, ground truth, predicted)\n",
    "filename = '200ep-10b-pred-a.npz'\n",
    "np.savez_compressed(filename, valid_dt[0], valid_dt[1], pred_img)\n",
    "print('Saved dataset: ', filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 source/ generated/ ground truth 이미지 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three images\n",
    "def get_3_image(one, two, three, vmin, vmax):\n",
    "    def current_slice(idx):\n",
    "        title = ['Source', 'Generated', 'Expected']\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15*3, 15))\n",
    "        ax = ax.flatten()\n",
    "        ax[0].imshow(one[idx, ...], vmin=vmin, vmax=vmax)\n",
    "        ax[1].imshow(two[idx, ...], vmin=vmin, vmax=vmax)\n",
    "        ax[2].imshow(three[idx, ...], vmin=vmin, vmax=vmax)\n",
    "        ax[0].set_title(title[0], fontsize=50)\n",
    "        ax[1].set_title(title[1], fontsize=50)\n",
    "        ax[2].set_title(title[2], fontsize=50)\n",
    "        plt.show()\n",
    "    return current_slice\n",
    "\n",
    "def sliceimageview_3(one, two, three):\n",
    "    from ipywidgets import IntSlider, interact\n",
    "    current_slice = get_3_image(one, two, three, vmin=-0.01, vmax=0.5)\n",
    "    num_slices = one.shape[0]\n",
    "    num_slices = two.shape[0]\n",
    "    num_slices = three.shape[0]\n",
    "    step_slider = IntSlider(min=0, max=num_slices-1, value=num_slices//2)\n",
    "    interact(current_slice, idx=step_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliceimageview_3(valid_dt[0], pred_img, valid_dt[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov  4 2022, 13:42:51) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02aaae3c9b50b62c88d0cc652c4ef3b1b4bf05515e9d7a066ea77f7c79246682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
